# 03_Evaluation_Metrics

Evaluation metrics are used to measure the quality of the statistical or machine learning model. Choosing the right metric is crucial for a project's success.

### Metrics for Classification:

-   **Accuracy**: The proportion of correct predictions.
-   **Confusion Matrix**: A table showing True Positives, True Negatives, False Positives, and False Negatives.
-   **Precision**: The proportion of positive identifications that was actually correct.
-   **Recall (Sensitivity)**: The proportion of actual positives that was identified correctly.
-   **F1-Score**: The harmonic mean of precision and recall.
-   **AUC-ROC Curve**: A performance measurement for the classification problems at various threshold settings.

### Metrics for Regression:

-   **Mean Absolute Error (MAE)**: The average of the absolute differences between predictions and actual values.
-   **Mean Squared Error (MSE)**: The average of the squared differences between predictions and actual values.
-   **R-squared (RÂ²)**: The proportion of the variance in the dependent variable that is predictable from the independent variable(s).

### Metrics for Clustering:

-   **Silhouette Score**: Measures how similar a data point is to its own cluster compared to other clusters. 