# Generative Adversarial Networks (GANs)

Generative Adversarial Networks, introduced by Ian Goodfellow et al. in 2014, represent a revolutionary approach to generative modeling through adversarial training. GANs consist of two neural networks engaged in a minimax game: a generator network that learns to create realistic data samples, and a discriminator network that learns to distinguish between real and generated data. This adversarial framework creates a powerful training dynamic where both networks improve simultaneously, leading to high-quality sample generation. The mathematical foundation of GANs combines game theory, probability theory, and deep learning optimization to create one of the most influential architectures in modern AI.

## Mathematical Foundation

### Basic GAN Formulation

**Generator Network:**
```
G_Î¸: z â†’ x
x_fake = G_Î¸(z), where z ~ p_z(z)
```

**Discriminator Network:**
```
D_Ï†: x â†’ [0, 1]
D_Ï†(x) = P(x is real)
```

**Minimax Game:**
```
min_Î¸ max_Ï† V(D, G) = E_{x~p_data(x)}[log D_Ï†(x)] + E_{z~p_z(z)}[log(1 - D_Ï†(G_Î¸(z)))]
```

Where:
- **Î¸**: Generator parameters
- **Ï†**: Discriminator parameters
- **p_data(x)**: Real data distribution
- **p_z(z)**: Prior noise distribution (typically N(0, I))

### Optimal Discriminator Analysis

**Fixed Generator Optimal Discriminator:**
For fixed G, the optimal discriminator is:
```
D*_G(x) = p_data(x) / (p_data(x) + p_g(x))
```

Where p_g(x) is the generator's distribution.

**Derivation:**
```
V(D, G) = âˆ«_x [p_data(x) log D(x) + p_g(x) log(1 - D(x))] dx
```

Taking derivative w.r.t. D(x) and setting to zero:
```
âˆ‚V/âˆ‚D(x) = p_data(x)/D(x) - p_g(x)/(1 - D(x)) = 0
```

Solving yields the optimal discriminator formula.

### Global Optimum Analysis

**Value Function with Optimal Discriminator:**
```
C(G) = max_D V(D, G) = E_{x~p_data}[log(p_data(x)/(p_data(x) + p_g(x)))] + 
                       E_{x~p_g}[log(p_g(x)/(p_data(x) + p_g(x)))]
```

**Jensen-Shannon Divergence:**
```
C(G) = -log(4) + 2 Ã— JS(p_data || p_g)
```

Where:
```
JS(p || q) = Â½KL(p || (p+q)/2) + Â½KL(q || (p+q)/2)
```

**Global Minimum:**
```
C(G) is minimized when p_g = p_data
At optimum: D*(x) = Â½ for all x
```

## Training Dynamics

### Alternating Optimization

**Algorithm 1: Basic GAN Training**
```
for epoch in epochs:
    # Train Discriminator
    for k steps:
        Sample {xâ½â±â¾}áµ¢â‚Œâ‚áµ ~ p_data(x)
        Sample {zâ½â±â¾}áµ¢â‚Œâ‚áµ ~ p_z(z)
        L_D = -(1/m)[âˆ‘áµ¢ log D(xâ½â±â¾) + âˆ‘áµ¢ log(1 - D(G(zâ½â±â¾)))]
        Ï† â† Ï† + Î·_D âˆ‡_Ï† L_D
    
    # Train Generator  
    Sample {zâ½â±â¾}áµ¢â‚Œâ‚áµ ~ p_z(z)
    L_G = -(1/m)âˆ‘áµ¢ log D(G(zâ½â±â¾))
    Î¸ â† Î¸ - Î·_G âˆ‡_Î¸ L_G
```

### Gradient Analysis

**Discriminator Gradients:**
```
âˆ‡_Ï† L_D = E_{x~p_data}[âˆ‡_Ï† log D_Ï†(x)] + E_{z~p_z}[âˆ‡_Ï† log(1 - D_Ï†(G_Î¸(z)))]
```

**Generator Gradients:**
```
âˆ‡_Î¸ L_G = E_{z~p_z}[âˆ‡_Î¸ log D_Ï†(G_Î¸(z))]
        = E_{z~p_z}[âˆ‡_Î¸ G_Î¸(z) â‹… âˆ‡_x log D_Ï†(x)|_{x=G_Î¸(z)}]
```

## Common Training Problems

### Vanishing Gradients

**Problem:** When discriminator becomes too strong:
```
D(G(z)) â‰ˆ 0 âŸ¹ log D(G(z)) â‰ˆ -âˆ
âˆ‡_Î¸ log D(G(z)) â‰ˆ 0
```

**Solution - Alternative Generator Loss:**
```
L_G = -E_{z~p_z}[log D(G(z))]  # Instead of E[log(1 - D(G(z)))]
```

**Mathematical Justification:**
Both losses have the same fixed point, but different gradients:
```
Original: âˆ‡_Î¸ E[log(1 - D(G(z)))] = -E[(âˆ‡_Î¸ G(z)) â‹… (âˆ‡_x D(x)|_{x=G(z)})/(1 - D(G(z)))]
Alternative: âˆ‡_Î¸ E[log D(G(z))] = E[(âˆ‡_Î¸ G(z)) â‹… (âˆ‡_x D(x)|_{x=G(z)})/D(G(z))]
```

### Mode Collapse

**Mathematical Description:**
Generator maps multiple z values to same x:
```
G(zâ‚) = G(zâ‚‚) = ... = x* for diverse zâ‚, zâ‚‚, ...
```

**Lack of Diversity:**
```
H(p_g) â‰ª H(p_data)  # Generated distribution has low entropy
```

### Nash Equilibrium

**Simultaneous Optimization:**
```
âˆ‡_Î¸ L_G(Î¸*, Ï†*) = 0
âˆ‡_Ï† L_D(Î¸*, Ï†*) = 0
```

**Challenges:**
- Non-convex optimization landscape
- No guarantee of convergence
- Oscillatory behavior possible

## GAN Variants and Improvements

### Deep Convolutional GAN (DCGAN)

**Architecture Guidelines:**
```
Generator:
- Use transposed convolutions for upsampling
- BatchNorm in all layers except output
- ReLU activation in all layers except output (Tanh)
- No fully connected layers

Discriminator:
- Use strided convolutions for downsampling  
- BatchNorm in all layers except input
- LeakyReLU activation
- No fully connected layers except output
```

**Mathematical Formulation:**
```
G: z âˆˆ â„Â¹â°â° â†’ x âˆˆ â„Â³Ë£â¶â´Ë£â¶â´
D: x âˆˆ â„Â³Ë£â¶â´Ë£â¶â´ â†’ [0, 1]
```

### Wasserstein GAN (WGAN)

**Earth Mover's Distance:**
```
W(p_data, p_g) = inf_{Î³âˆˆÎ (p_data,p_g)} E_{(x,y)~Î³}[||x - y||]
```

**Kantorovich-Rubinstein Duality:**
```
W(p_data, p_g) = sup_{||f||_Lâ‰¤1} E_{x~p_data}[f(x)] - E_{x~p_g}[f(x)]
```

**WGAN Objective:**
```
min_G max_{Dâˆˆğ’Ÿ} E_{x~p_data}[D(x)] - E_{z~p_z}[D(G(z))]
```

Where ğ’Ÿ is the set of 1-Lipschitz functions.

**Weight Clipping:**
```
w â† clip(w, -c, c)  # After each discriminator update
```

### WGAN-GP (Gradient Penalty)

**Gradient Penalty Term:**
```
Î» E_{xÌ‚~p_xÌ‚}[(||âˆ‡_{xÌ‚} D(xÌ‚)||â‚‚ - 1)Â²]
```

**Interpolated Samples:**
```
xÌ‚ = Îµx + (1-Îµ)G(z), where Îµ ~ U[0,1]
```

**Complete WGAN-GP Loss:**
```
L = E_{x~p_data}[D(x)] - E_{z~p_z}[D(G(z))] + Î» E_{xÌ‚~p_xÌ‚}[(||âˆ‡_{xÌ‚} D(xÌ‚)||â‚‚ - 1)Â²]
```

### Least Squares GAN (LSGAN)

**Modified Loss Functions:**
```
L_D = Â½E_{x~p_data}[(D(x) - 1)Â²] + Â½E_{z~p_z}[D(G(z))Â²]
L_G = Â½E_{z~p_z}[(D(G(z)) - 1)Â²]
```

**Motivation:** Penalizes samples far from decision boundary.

### Spectral Normalization GAN (SNGAN)

**Spectral Norm:**
```
SN(W) = W / Ïƒ(W)
```

Where Ïƒ(W) is the largest singular value of W.

**Lipschitz Constraint:**
```
||f||_L â‰¤ âˆ_l Ïƒ(W^{(l)})
```

**Power Iteration Method:**
```
u^{(t+1)} = W^T v^{(t)} / ||W^T v^{(t)}||â‚‚
v^{(t+1)} = W u^{(t+1)} / ||W u^{(t+1)}||â‚‚
Ïƒ(W) â‰ˆ u^{(T)T} W v^{(T)}
```

## Conditional GANs

### Class-Conditional Generation

**Generator:**
```
x = G(z, y), where y is class label
```

**Discriminator:**
```
D(x, y) â†’ [0, 1]
```

**Loss Functions:**
```
L_D = -E_{(x,y)~p_data}[log D(x,y)] - E_{z~p_z,y~p_y}[log(1 - D(G(z,y),y))]
L_G = -E_{z~p_z,y~p_y}[log D(G(z,y),y)]
```

### Auxiliary Classifier GAN (AC-GAN)

**Discriminator with Classifier:**
```
D(x) â†’ (real/fake score, class probabilities)
```

**Loss Functions:**
```
L_S = E[(log P(S=real|x_real)) + (log P(S=fake|G(z)))]  # Source loss
L_C = E[(log P(C=c|x_real)) + (log P(C=c|G(z)))]        # Class loss
L_D = L_S + L_C
L_G = L_C - L_S
```

### Pix2Pix

**Paired Image Translation:**
```
G: (x, z) â†’ y
D: (x, y) â†’ [0, 1]
```

**L1 Regularization:**
```
L_L1 = E_{x,y,z}[||y - G(x,z)||â‚]
```

**Total Loss:**
```
L_G = E_{x,z}[log D(x,G(x,z))] + Î» L_L1
```

### CycleGAN

**Cycle Consistency:**
```
F: X â†’ Y, G: Y â†’ X
L_cyc = E_{x~X}[||G(F(x)) - x||â‚] + E_{y~Y}[||F(G(y)) - y||â‚]
```

**Total Loss:**
```
L = L_GAN(G,D_Y,X,Y) + L_GAN(F,D_X,Y,X) + Î» L_cyc
```

## Progressive Training

### Progressive GAN

**Resolution Scaling:**
```
4Ã—4 â†’ 8Ã—8 â†’ 16Ã—16 â†’ 32Ã—32 â†’ 64Ã—64 â†’ ...
```

**Smooth Transition:**
```
output = Î± Ã— higher_res + (1-Î±) Ã— upsampled_lower_res
Î±: 0 â†’ 1 during transition
```

**Mathematical Formulation:**
```
G_k(z) = ToRGB_k(g_k(...g_1(z)...))
G_{k+1}(z) = Î± Ã— ToRGB_{k+1}(g_{k+1}(g_k(...g_1(z)...))) + 
             (1-Î±) Ã— Upsample(ToRGB_k(g_k(...g_1(z)...)))
```

### StyleGAN

**Style-Based Generator:**
```
w = MLP(z)                    # Mapping network
y_{l,i} = Affine_l(w)         # Style vector for layer l
x_l = Modulation(x_{l-1}, y_{l,i})  # Feature modulation
```

**Adaptive Instance Normalization:**
```
AdaIN(x_i, y) = y_{s,i} Ã— (x_i - Î¼(x_i))/Ïƒ(x_i) + y_{b,i}
```

Where:
- y_{s,i}: Style scale
- y_{b,i}: Style bias

**Noise Injection:**
```
x_l = x_l + B_l Ã— noise_l
```

## Training Techniques

### Feature Matching

**Modified Generator Loss:**
```
L_G = ||E_{x~p_data}[f(x)] - E_{z~p_z}[f(G(z))]||â‚‚Â²
```

Where f(x) is intermediate features from discriminator.

### Mini-batch Discrimination

**Batch Statistics:**
```
M_i = f(x_i) âˆˆ â„á´¬
o_i = âˆ‘_{j=1}^n exp(-||M_i - M_j||_B)
```

**Augmented Features:**
```
h'_i = [h_i, o_i]  # Concatenate original and batch features
```

### Historical Averaging

**Parameter Regularization:**
```
L_reg = ||Î¸ - (1/t)âˆ‘_{i=1}^t Î¸_i||â‚‚Â²
```

**Total Loss:**
```
L_total = L_original + Î» L_reg
```

### Experience Replay

**Discriminator Training:**
```
# Mix current and historical generated samples
batch = [current_generated, sample_from_history]
```

**Generator History Buffer:**
Maintain buffer of previously generated samples.

## Evaluation Metrics

### Inception Score (IS)

**Mathematical Definition:**
```
IS = exp(E_x[KL(p(y|x) || p(y))])
```

Where:
- p(y|x): Inception network predictions
- p(y): Marginal distribution

**Properties:**
- Higher IS â†’ Better quality and diversity
- Range: [1, num_classes]

### FrÃ©chet Inception Distance (FID)

**Gaussian Assumption:**
```
X_real ~ N(Î¼_r, Î£_r)
X_generated ~ N(Î¼_g, Î£_g)
```

**FID Calculation:**
```
FID = ||Î¼_r - Î¼_g||â‚‚Â² + Tr(Î£_r + Î£_g - 2(Î£_r Î£_g)^{1/2})
```

**Lower FID â†’ Better quality**

### Precision and Recall

**Manifold-Based Metrics:**
```
Precision = |{generated samples in real manifold}| / |{generated samples}|
Recall = |{real samples in generated manifold}| / |{real samples}|
```

**k-NN Estimation:**
Use k-nearest neighbors in feature space to estimate manifolds.

## Theoretical Analysis

### Convergence Analysis

**Fixed Point Analysis:**
For simultaneous gradient descent:
```
Î¸_{t+1} = Î¸_t - Î·_G âˆ‡_Î¸ L_G(Î¸_t, Ï†_t)
Ï†_{t+1} = Ï†_t + Î·_D âˆ‡_Ï† L_D(Î¸_t, Ï†_t)
```

**Jacobian Matrix:**
```
J = [âˆ‚âˆ‡_Î¸ L_G/âˆ‚Î¸    âˆ‚âˆ‡_Î¸ L_G/âˆ‚Ï†]
    [âˆ‚âˆ‡_Ï† L_D/âˆ‚Î¸    âˆ‚âˆ‡_Ï† L_D/âˆ‚Ï†]
```

**Stability Condition:**
Eigenvalues of J must have negative real parts.

### Non-Saturating Game

**Alternative Formulation:**
```
max_Î¸ min_Ï† V(Î¸, Ï†) = E_{z~p_z}[log D_Ï†(G_Î¸(z))] - E_{x~p_data}[log D_Ï†(x)]
```

**Comparison with Original:**
- Same Nash equilibria
- Different gradient dynamics
- Better convergence properties

### Mode Collapse Theory

**Perfect Discriminator Scenario:**
If D is perfect classifier:
```
âˆ‡_Î¸ L_G = 0  (everywhere)
```

**Unrolled GANs Solution:**
```
Î¸_{t+1} = Î¸_t - Î·_G âˆ‡_Î¸ L_G(Î¸_t, Ï†_t^{(k)})
```

Where Ï†_t^{(k)} is k-step lookahead discriminator update.

## Information-Theoretic GANs

### InfoGAN

**Mutual Information Maximization:**
```
min_{G,Q} max_D V_I(D,G) = V(D,G) - Î» I(c; G(z,c))
```

Where:
- c: Latent code
- I(c; G(z,c)): Mutual information

**Variational Lower Bound:**
```
I(c; G(z,c)) â‰¥ E_{x~G(z,c)}[E_{c'~p(c|x)}[log Q(c'|x)]] + H(c)
```

### BiGAN/ALI

**Bidirectional Mapping:**
```
Generator: G(z) â†’ x
Encoder: E(x) â†’ z
```

**Joint Discriminator:**
```
D(x, z) â†’ [0, 1]
```

**Adversarial Loss:**
```
L = E_{x~p_data}[log D(x, E(x))] + E_{z~p_z}[log(1 - D(G(z), z))]
```

## Advanced Architectures

### Self-Attention GAN (SAGAN)

**Self-Attention Module:**
```
Attention(x) = softmax(f(x)^T g(x)) h(x)
```

Where:
```
f(x) = W_f x  # Query
g(x) = W_g x  # Key  
h(x) = W_h x  # Value
```

**Generator Integration:**
```
x_{l+1} = Î³ Ã— Attention(x_l) + x_l
```

### BigGAN

**Class-Conditional Batch Normalization:**
```
BN(x, y) = Î³(y) Ã— (x - Î¼)/Ïƒ + Î²(y)
```

**Orthogonal Regularization:**
```
R_orth = Î» ||W^T W - I||_FÂ²
```

**Truncated Normal Sampling:**
```
z ~ TruncatedNormal(0, I, threshold)
```

### Progressive Growing

**Smooth Layer Introduction:**
```
G_Î± = (1-Î±) Ã— Upsample(G_{k-1}) + Î± Ã— G_k
D_Î± = (1-Î±) Ã— Downsample(D_{k-1}) + Î± Ã— D_k
```

**Î± Schedule:**
```
Î±(t) = min(1, (t - t_start)/t_transition)
```

## Regularization Techniques

### Spectral Normalization

**Implementation:**
```
W_SN = W / Ïƒ_1(W)
```

**Power Iteration:**
```
for i in range(n_iterations):
    v = W^T u / ||W^T u||
    u = W v / ||W v||
Ïƒ_1 â‰ˆ u^T W v
```

### Gradient Penalty Variants

**Zero-Centered GP:**
```
L_GP = Î» E_{xÌ‚}[(||âˆ‡_{xÌ‚} D(xÌ‚)||â‚‚ - 0)Â²]
```

**LP (Lipschitz Penalty):**
```
L_LP = Î» max(0, ||âˆ‡_{xÌ‚} D(xÌ‚)||â‚‚ - 1)Â²
```

## Applications

### Image Generation

**High-Resolution Synthesis:**
```
z âˆˆ â„^d â†’ x âˆˆ â„^{3Ã—1024Ã—1024}
```

**Style Transfer:**
```
content + style â†’ stylized_image
```

### Data Augmentation

**Training Set Expansion:**
```
Original: {xâ‚, xâ‚‚, ..., x_n}
Augmented: {xâ‚, ..., x_n, G(zâ‚), ..., G(z_m)}
```

**Domain Adaptation:**
```
Source domain â†’ Target domain
```

### Anomaly Detection

**Reconstruction-Based:**
```
anomaly_score = ||x - G(E(x))||â‚‚Â²
```

**Discriminator-Based:**
```
anomaly_score = 1 - D(x)
```

## Implementation Considerations

### Numerical Stability

**Label Smoothing:**
```
Real labels: 0.9 instead of 1.0
Fake labels: 0.1 instead of 0.0
```

**Noisy Labels:**
```
P(label_flip) = Î±
Real â†’ Fake with probability Î±
Fake â†’ Real with probability Î±
```

### Hyperparameter Tuning

**Learning Rate Balance:**
```
Î·_G / Î·_D â‰ˆ 1:1 to 1:5  # Generator : Discriminator
```

**Batch Size Effects:**
```
Larger batches â†’ Better gradient estimates
Smaller batches â†’ More noise, potential regularization
```

### Monitoring Training

**Loss Patterns:**
```
Healthy: L_D â‰ˆ log(2), L_G â‰ˆ log(2)
Mode collapse: L_G â†’ -âˆ, L_D â†’ 0
Discriminator wins: L_G â†’ âˆ, L_D â†’ 0
```

**Generated Sample Quality:**
Monitor visual quality and diversity throughout training.

## Mathematical Summary

Generative Adversarial Networks represent a game-theoretic approach to generative modeling:

1. **Adversarial Framework**: Two networks compete in a minimax game, driving each other to improve
2. **Nash Equilibrium**: Theoretical optimal point where generator matches data distribution  
3. **Implicit Density Models**: No explicit likelihood function, but powerful sample generation
4. **Rich Theoretical Foundation**: Connections to optimal transport, information theory, and game theory

**Key Mathematical Insight**: The adversarial loss function transforms generative modeling from a density estimation problem into a discrimination problem. The minimax objective creates a training dynamic where the generator learns to produce samples indistinguishable from real data.

**Theoretical Foundation**: GANs can be viewed as:
- **Density Ratio Estimation**: Discriminator estimates density ratios  
- **Optimal Transport**: Wasserstein GANs minimize earth mover's distance
- **Variational Divergence Minimization**: Different GAN variants minimize different f-divergences
- **Game Theory**: Two-player zero-sum game with provable optimal strategies

The mathematical elegance of GANs lies in their simplicity - a single adversarial objective leads to complex, realistic data generation, making them one of the most influential architectures in modern generative modeling. 