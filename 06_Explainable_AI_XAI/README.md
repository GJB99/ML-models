# 06_Explainable_AI_XAI

As models become more complex, understanding *why* they make certain predictions becomes critical for trust, debugging, and ethical considerations. Explainable AI (XAI) is the field dedicated to developing methods that explain and interpret the decisions of machine learning models.

### Topics Covered:

-   **LIME (Local Interpretable Model-agnostic Explanations)**: A technique that explains the prediction of any classifier by learning a simpler, interpretable model around the prediction.
-   **SHAP (SHapley Additive exPlanations)**: A game theory approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations.
-   **Attention Visualization**: A method to understand what parts of the input a model is "focusing" on, particularly in Transformer-based models. 